{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T16:35:02.276573090Z",
     "start_time": "2023-08-01T16:35:01.899542484Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T16:35:12.094224676Z",
     "start_time": "2023-08-01T16:35:12.049464438Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Binary  Reference Size  Reduced Size  Difference (%)\n",
      "0     date-8.21           94240       34341.0      -63.560059\n",
      "1    grep-2.4.2          162640       95661.0      -41.182366\n",
      "2      gzip-1.3          104152       68320.0      -34.403564\n",
      "3   mkdir-5.2.1           49360       22160.0      -55.105348\n",
      "4  printtokens2           21176       21181.0        0.023612\n",
      "5     sed-4.1.5          174472      109617.0      -37.172154\n"
     ]
    }
   ],
   "source": [
    "def calculate_mean_size(folder_path, binaries):\n",
    "    binary_sizes = {}\n",
    "    for binary in binaries:\n",
    "        binary_sizes[binary] = []\n",
    "        for root, _, files in os.walk(folder_path):\n",
    "            for file in files:\n",
    "                if any(name in file for name in binaries[binary]):\n",
    "                    file_path = os.path.join(root, file)\n",
    "                    size = os.path.getsize(file_path)\n",
    "                    binary_sizes[binary].append(size)\n",
    "\n",
    "    return {binary: mean(sizes) if sizes else 0 for binary, sizes in binary_sizes.items()}\n",
    "\n",
    "def create_dataframe(ref_folder, targeted_directories, studied_binaries, ref_binaries):\n",
    "    ref_sizes = calculate_mean_size(ref_folder, ref_binaries)\n",
    "    targeted_sizes = {}\n",
    "\n",
    "    for targeted_folder in targeted_directories:\n",
    "        targeted_sizes[targeted_folder] = calculate_mean_size(targeted_folder, studied_binaries)\n",
    "    \n",
    "    raw_result = {\"Program\":[],\"bloated\":[],\"chisel\":[],\"debop\":[],\"cov\":[]}\n",
    "    for binary, ref_size in ref_sizes.items():\n",
    "        raw_result[\"Program\"].append(binary)\n",
    "        raw_result[\"bloated\"].append(round(ref_size,2))\n",
    "        raw_result[\"chisel\"].append(targeted_sizes[targeted_directories[0]].get(binary, 0))\n",
    "        raw_result[\"debop\"].append(targeted_sizes[targeted_directories[1]].get(binary, 1))\n",
    "        raw_result[\"cov\"].append(targeted_sizes[targeted_directories[2]].get(binary, 2))\n",
    "\n",
    "    raw_result_df = pd.DataFrame(raw_result)\n",
    "    raw_result_df[\"Program\"]=raw_result_df[\"Program\"].str.split('-').str[0]\n",
    "    raw_result_df.to_csv('./debloating_results/debloat_experiments_size.csv', encoding='utf-8', sep=';',index_label=\"Nr\")\n",
    "\n",
    "    data = {\"Binary\": [], \"Reference Size\": [], \"Reduced Size\": [], \"Difference (%)\":[]}\n",
    "\n",
    "    for binary, ref_size in ref_sizes.items():\n",
    "        data[\"Binary\"].append(binary)\n",
    "        data[\"Reference Size\"].append(round(ref_size,2))\n",
    "        reduced_size=round(mean(targeted_sizes[t].get(binary, 0) for t in targeted_directories),0)\n",
    "        data[\"Reduced Size\"].append(reduced_size)\n",
    "        percentage_difference = 100 * ((reduced_size - ref_size) / ref_size) if ref_size != 0 else 0\n",
    "        data[\"Difference (%)\"].append(percentage_difference)\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "ref_folder = \"../inputs/bloated/\"\n",
    "targeted_directories = [\"../inputs/debloated/chisel/\", \"../inputs/debloated/debop/\",\"../inputs/debloated/cov/\"]\n",
    "\n",
    "studied_binaries= {\n",
    "\"date-8.21\": [\"date-8.21_I2\"],\n",
    "\"grep-2.4.2\": [\"grep-2.4.2_p0.2train\"],\n",
    "\"gzip-1.3\":[\"gzip-1.3_p0.2train\"],\n",
    "\"mkdir-5.2.1\":[\"mkdir-5.2.1_I0\",\"mkdir-5.2.1_I5\"],\n",
    "\"printtokens2\":[\"printtokens2_p0.3train\",\"printtokens2_p0.2train\"],\n",
    "\"sed-4.1.5\": [\"sed-4.1.5_p0.1train\",\"sed-4.1.5_p0.3train\"]\n",
    "}\n",
    "\n",
    "ref_binaries= {\n",
    "\"date-8.21\": [\"date-8.21\"],\n",
    "\"grep-2.4.2\": [\"grep-2.4.2\"],\n",
    "\"gzip-1.3\":[\"gzip-1.3\"],\n",
    "\"mkdir-5.2.1\":[\"mkdir-5.2.1\"],\n",
    "\"printtokens2\":[\"printtokens2\"],\n",
    "\"sed-4.1.5\": [\"sed-4.1.5\"]\n",
    "}\n",
    "result_df = create_dataframe(ref_folder, targeted_directories, studied_binaries,ref_binaries)\n",
    "print(result_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
